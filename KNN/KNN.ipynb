{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook that will evaluate the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraires to use\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.neighbors as skl_nb\n",
    "import sklearn.model_selection as skl_ms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#need to get the processing python file in another directory\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from process_data import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['snow']\n",
      "New columns: ['good_weather' 'is_day' 'temp_fahrenheit']\n",
      "Split: \"train\" \t[Size: 1280] \t[Prec: 0.8]\n",
      "\tX: (1280, 17)\n",
      "\tY: (1280,)\n",
      "Split: \"test\" \t[Size: 320] \t[Prec: 0.2]\n",
      "\tX: (320, 17)\n",
      "\tY: (320,)\n",
      "      hour_of_day  day_of_week     month   holiday   weekday  summertime  \\\n",
      "0        0.558988    -1.017343 -0.709870 -0.184189  0.643712    0.751527   \n",
      "1       -1.625091    -1.516270  0.152211 -0.184189  0.643712    0.751527   \n",
      "2        1.141408    -0.518416  1.014292 -0.184189  0.643712    0.751527   \n",
      "3       -1.625091     1.477292 -0.135149 -0.184189 -1.553491    0.751527   \n",
      "4        1.287014    -1.017343  0.726932 -0.184189  0.643712    0.751527   \n",
      "...           ...          ...       ...       ...       ...         ...   \n",
      "1275     1.723829     0.978365  0.439572 -0.184189 -1.553491    0.751527   \n",
      "1276    -1.625091     0.978365  1.589013 -0.184189 -1.553491   -1.330625   \n",
      "1277    -0.605854    -0.518416  0.726932 -0.184189  0.643712    0.751527   \n",
      "1278    -0.023433    -0.019489 -0.997230 -0.184189  0.643712    0.751527   \n",
      "1279    -0.605854    -1.516270 -0.422510 -0.184189  0.643712    0.751527   \n",
      "\n",
      "          temp       dew  humidity    precip  snowdepth  windspeed  \\\n",
      "0     1.073206  0.506614 -0.935864 -0.130133  -0.105593   0.664882   \n",
      "1     1.277959  1.445451  0.574511 -0.130133  -0.105593  -0.392781   \n",
      "2     0.631369  1.015983  0.966110 -0.130133  -0.105593  -0.724097   \n",
      "3     1.040876  1.335587  0.820569 -0.000790  -0.105593  -0.086951   \n",
      "4     0.340403 -0.332346 -1.268303 -0.130133  -0.105593   0.014993   \n",
      "...        ...       ...       ...       ...        ...        ...   \n",
      "1275  0.685251  1.075909  0.980768 -0.130133  -0.105593   0.282594   \n",
      "1276 -1.243744 -0.781789  0.644141 -0.130133  -0.105593  -1.654331   \n",
      "1277  0.825346  1.355562  1.398543 -0.130133  -0.105593  -0.507467   \n",
      "1278 -0.554047  0.117097  1.498536 -0.073222  -0.105593  -0.239866   \n",
      "1279 -0.133763 -0.042705  0.018002 -0.130133  -0.105593   1.569630   \n",
      "\n",
      "      cloudcover  visibility  temp_fahrenheit  good_weather    is_day  \n",
      "0      -1.233517    0.283313         1.068775      0.782355  1.267645  \n",
      "1      -1.233517    0.283313         1.248354      1.310216 -0.788864  \n",
      "2       0.506560    0.283313         0.649758      0.935465 -0.788864  \n",
      "3       0.956106   -0.857198         1.008915      1.190262 -0.788864  \n",
      "4      -1.123424    0.283313         0.350459      0.183458 -0.788864  \n",
      "...          ...         ...              ...           ...       ...  \n",
      "1275    0.506560    0.283313         0.709617      0.965596 -0.788864  \n",
      "1276   -1.979701    0.283313        -1.265751     -1.155562 -0.788864  \n",
      "1277   -0.178461    0.283313         0.829337      1.149995 -0.788864  \n",
      "1278    1.078431    0.156589        -0.547435      0.175148  1.267645  \n",
      "1279    0.738978    0.283313        -0.128418      0.191332 -0.788864  \n",
      "\n",
      "[1280 rows x 17 columns]\n",
      "      increase_stock\n",
      "0                  1\n",
      "1                  0\n",
      "2                  1\n",
      "3                  0\n",
      "4                  0\n",
      "...              ...\n",
      "1275               0\n",
      "1276               0\n",
      "1277               0\n",
      "1278               0\n",
      "1279               0\n",
      "\n",
      "[1280 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#getting the percentage splits of our training and testing data\n",
    "split_prec = {\n",
    "    'train': 0.8, \n",
    "    'test': 0.2,\n",
    "}\n",
    "#whatever scaler we will use\n",
    "scaler = skl_pre.StandardScaler()\n",
    "\n",
    "#get the training and testing data\n",
    "X_train, X_test, Y_train, Y_test = process_data(split_prec, scaler,is_random=False)\n",
    "print(X_train)\n",
    "# print(X_test)\n",
    "print(Y_train)\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training we will only be working with X_train from here on down\n",
    "Now that we have our training and test data we will run a KNN model on the training data with k-fold validation for hyperparameter tunning (what is a good value of k, distance measure to use, ect...). Then once we have a decent value of k we will \"retrain\" the model on the entire training data set and use that model on the test data which has never been seen and use the error from that as an estimation of $E_{new}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a trained KNN classifier that uses cross validation and grid search to find the best hyperparameters\n",
    "def get_fitted_KNN(X,Y):\n",
    "    #these are the hyperparameters that we are using Gridsearch to find\n",
    "    parameters = {\"n_neighbors\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], \"p\" : [1,2,3]}\n",
    "    #running grid search over a KNN model with 25 fold cross validation.\n",
    "    classifier = skl_ms.GridSearchCV(skl_nb.KNeighborsClassifier(), parameters, cv=25)\n",
    "    #fit the best classifier\n",
    "    classifier.fit(X,Y)\n",
    "    #return it\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the expected $E_{train}$ of our model when we run cross validation over training to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 11, 'p': 1}\n",
      "0.8694720965309201\n",
      "{'n_neighbors': 11, 'p': 1}\n",
      "0.8694720965309201\n",
      "{'n_neighbors': 11, 'p': 1}\n",
      "0.8694720965309201\n",
      "{'n_neighbors': 11, 'p': 1}\n",
      "0.8694720965309201\n",
      "{'n_neighbors': 11, 'p': 1}\n",
      "0.8694720965309201\n",
      "{'n_neighbors': 11, 'p': 1}\n",
      "0.8694720965309201\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# print(np.array(Y_train.values.tolist()).reshape(-1,))\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m get_fitted_KNN(X_train,np\u001b[38;5;241m.\u001b[39marray(Y_train\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classifier\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classifier\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "Cell \u001b[1;32mIn[83], line 5\u001b[0m, in \u001b[0;36mget_fitted_KNN\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m      3\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m17\u001b[39m,\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m19\u001b[39m,\u001b[38;5;241m20\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]}\n\u001b[0;32m      4\u001b[0m classifier \u001b[38;5;241m=\u001b[39m skl_ms\u001b[38;5;241m.\u001b[39mGridSearchCV(skl_nb\u001b[38;5;241m.\u001b[39mKNeighborsClassifier(), parameters, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(X,Y)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classifier\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:910\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    907\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    909\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 910\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m _score(\n\u001b[0;32m    911\u001b[0m     estimator, X_test, y_test, scorer, score_params_test, error_score\n\u001b[0;32m    912\u001b[0m )\n\u001b[0;32m    913\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[0;32m    969\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, y_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:455\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    454\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:764\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:295\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, classes_k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes_):\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 295\u001b[0m         mode, _ \u001b[38;5;241m=\u001b[39m _mode(_y[neigh_ind, k], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m         mode, _ \u001b[38;5;241m=\u001b[39m weighted_mode(_y[neigh_ind, k], weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py:101\u001b[0m, in \u001b[0;36m_mode\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mode\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.9.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 101\u001b[0m         mode \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mmode(a, axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sp_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.10.999\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    103\u001b[0m             \u001b[38;5;66;03m# scipy.stats.mode has changed returned array shape with axis=None\u001b[39;00m\n\u001b[0;32m    104\u001b[0m             \u001b[38;5;66;03m# and keepdims=True, see https://github.com/scipy/scipy/pull/17561\u001b[39;00m\n\u001b[0;32m    105\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:603\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result_to_tuple(hypotest_fun_out(\u001b[38;5;241m*\u001b[39msamples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    602\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(x, axis, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 603\u001b[0m res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(hypotest_fun, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, arr\u001b[38;5;241m=\u001b[39mx)\n\u001b[0;32m    604\u001b[0m res \u001b[38;5;241m=\u001b[39m _add_reduced_axes(res, reduced_axes, keepdims)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuple_to_result(\u001b[38;5;241m*\u001b[39mres)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\numpy\\lib\\shape_base.py:402\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[1;32m--> 402\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m asanyarray(func1d(inarr_view[ind], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, matrix):\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# wrap the array, to preserve subclasses\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     buff \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39m__array_wrap__(buff)\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:600\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper.<locals>.hypotest_fun\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_too_small(samples, kwds):\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfull(n_out, NaN)\n\u001b[1;32m--> 600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_to_tuple(hypotest_fun_out(\u001b[38;5;241m*\u001b[39msamples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:528\u001b[0m, in \u001b[0;36mmode\u001b[1;34m(a, axis, nan_policy, keepdims)\u001b[0m\n\u001b[0;32m    525\u001b[0m     NaN \u001b[38;5;241m=\u001b[39m _get_nan(a)\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ModeResult(\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([NaN, \u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mNaN\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 528\u001b[0m vals, cnts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(a, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    529\u001b[0m modes, counts \u001b[38;5;241m=\u001b[39m vals[cnts\u001b[38;5;241m.\u001b[39margmax()], cnts\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModeResult(modes[()], counts[()])\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:363\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    361\u001b[0m     ret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (inv_idx,)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_counts:\n\u001b[1;32m--> 363\u001b[0m     idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(np\u001b[38;5;241m.\u001b[39mnonzero(mask) \u001b[38;5;241m+\u001b[39m ([mask\u001b[38;5;241m.\u001b[39msize],))\n\u001b[0;32m    364\u001b[0m     ret \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mdiff(idx),)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(np.array(Y_train.values.tolist()).reshape(-1,))\n",
    "for i in range(10):\n",
    "    classifier = get_fitted_KNN(X_train,np.array(Y_train.values.tolist()).reshape(-1,))\n",
    "    print(classifier.best_params_)\n",
    "    print(classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to evaluate a model with cross validation we can start hyperparameter tuning. Note we are focusing on Accuracy here because that is the test statistic we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will go through several different hyperparameters to hopefully tune the KNN model and find a good one\n",
    "def find_a_good_KNN(df = X_train.join(Y_train)):\n",
    "    parameters = {\"k\":}\n",
    "    x_cols = df.columns.to_list().remove(\"increase_stock\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnecessary code\n",
    "\n",
    "#this will run k_folds cross validation with the passed hyperparameters\n",
    "#returns the approximation of the accuracy of the model\n",
    "# def run_k_folds(df = X_train.join(Y_train), folds = 5):\n",
    "#     #setting up our kfolds cross validation\n",
    "#     kf = skl_ms.KFold(folds, shuffle= True)\n",
    "#     #getting the column list so we can separate into X and Y\n",
    "#     cols = df.columns.tolist()\n",
    "#     ycol = \"increase_stock\"\n",
    "#     #only the x columns\n",
    "#     cols.remove(ycol)\n",
    "#     #will be the mean accuracy of the model. This is what we return\n",
    "#     score = 0\n",
    "#     parameters = []\n",
    "#     # print(df)\n",
    "#     # print(cols)\n",
    "#     #loop through all the training and test data\n",
    "#     for i, (train_index, test_index) in enumerate(kf.split(df)):\n",
    "#         #get the specific training data\n",
    "#         train = df.loc[train_index]\n",
    "#         # print(train)\n",
    "#         #get the specific testing data\n",
    "#         test = df.loc[test_index]\n",
    "#         #make a KNN classifier and fit it \n",
    "#         classifier = get_fitted_KNN(X = train[cols], Y=train[ycol])\n",
    "#         #get the score using the k folds test data set\n",
    "#         print(classifier.best_params_)\n",
    "#         parameters.append(classifier.best_params_)\n",
    "#         score += classifier.score(test[cols], test[ycol])\n",
    "#     print(parameters)\n",
    "#     print(Counter(parameters))\n",
    "#     return score/folds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
