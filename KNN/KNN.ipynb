{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook that will evaluate the KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraires to use\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.neighbors as skl_nb\n",
    "import sklearn.model_selection as skl_ms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#need to get the processing python file in another directory\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from process_data import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['snow']\n",
      "New columns: ['good_weather' 'is_day' 'temp_fahrenheit']\n",
      "Split: \"train\" \t[Size: 1280] \t[Prec: 0.8]\n",
      "\tX: (1280, 17)\n",
      "\tY: (1280,)\n",
      "Split: \"test\" \t[Size: 320] \t[Prec: 0.2]\n",
      "\tX: (320, 17)\n",
      "\tY: (320,)\n",
      "      hour_of_day  day_of_week     month   holiday   weekday  summertime  \\\n",
      "0        0.558988    -1.017343 -0.709870 -0.184189  0.643712    0.751527   \n",
      "1       -1.625091    -1.516270  0.152211 -0.184189  0.643712    0.751527   \n",
      "2        1.141408    -0.518416  1.014292 -0.184189  0.643712    0.751527   \n",
      "3       -1.625091     1.477292 -0.135149 -0.184189 -1.553491    0.751527   \n",
      "4        1.287014    -1.017343  0.726932 -0.184189  0.643712    0.751527   \n",
      "...           ...          ...       ...       ...       ...         ...   \n",
      "1275     1.723829     0.978365  0.439572 -0.184189 -1.553491    0.751527   \n",
      "1276    -1.625091     0.978365  1.589013 -0.184189 -1.553491   -1.330625   \n",
      "1277    -0.605854    -0.518416  0.726932 -0.184189  0.643712    0.751527   \n",
      "1278    -0.023433    -0.019489 -0.997230 -0.184189  0.643712    0.751527   \n",
      "1279    -0.605854    -1.516270 -0.422510 -0.184189  0.643712    0.751527   \n",
      "\n",
      "          temp       dew  humidity    precip  snowdepth  windspeed  \\\n",
      "0     1.073206  0.506614 -0.935864 -0.130133  -0.105593   0.664882   \n",
      "1     1.277959  1.445451  0.574511 -0.130133  -0.105593  -0.392781   \n",
      "2     0.631369  1.015983  0.966110 -0.130133  -0.105593  -0.724097   \n",
      "3     1.040876  1.335587  0.820569 -0.000790  -0.105593  -0.086951   \n",
      "4     0.340403 -0.332346 -1.268303 -0.130133  -0.105593   0.014993   \n",
      "...        ...       ...       ...       ...        ...        ...   \n",
      "1275  0.685251  1.075909  0.980768 -0.130133  -0.105593   0.282594   \n",
      "1276 -1.243744 -0.781789  0.644141 -0.130133  -0.105593  -1.654331   \n",
      "1277  0.825346  1.355562  1.398543 -0.130133  -0.105593  -0.507467   \n",
      "1278 -0.554047  0.117097  1.498536 -0.073222  -0.105593  -0.239866   \n",
      "1279 -0.133763 -0.042705  0.018002 -0.130133  -0.105593   1.569630   \n",
      "\n",
      "      cloudcover  visibility  temp_fahrenheit  good_weather    is_day  \n",
      "0      -1.233517    0.283313         1.068775      0.782355  1.267645  \n",
      "1      -1.233517    0.283313         1.248354      1.310216 -0.788864  \n",
      "2       0.506560    0.283313         0.649758      0.935465 -0.788864  \n",
      "3       0.956106   -0.857198         1.008915      1.190262 -0.788864  \n",
      "4      -1.123424    0.283313         0.350459      0.183458 -0.788864  \n",
      "...          ...         ...              ...           ...       ...  \n",
      "1275    0.506560    0.283313         0.709617      0.965596 -0.788864  \n",
      "1276   -1.979701    0.283313        -1.265751     -1.155562 -0.788864  \n",
      "1277   -0.178461    0.283313         0.829337      1.149995 -0.788864  \n",
      "1278    1.078431    0.156589        -0.547435      0.175148  1.267645  \n",
      "1279    0.738978    0.283313        -0.128418      0.191332 -0.788864  \n",
      "\n",
      "[1280 rows x 17 columns]\n",
      "      increase_stock\n",
      "0                  1\n",
      "1                  0\n",
      "2                  1\n",
      "3                  0\n",
      "4                  0\n",
      "...              ...\n",
      "1275               0\n",
      "1276               0\n",
      "1277               0\n",
      "1278               0\n",
      "1279               0\n",
      "\n",
      "[1280 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#getting the percentage splits of our training and testing data\n",
    "split_prec = {\n",
    "    'train': 0.8, \n",
    "    'test': 0.2,\n",
    "}\n",
    "#whatever scaler we will use\n",
    "scaler = skl_pre.StandardScaler()\n",
    "\n",
    "#get the training and testing data\n",
    "X_train, X_test, Y_train, Y_test = process_data(split_prec, scaler,is_random=False)\n",
    "print(X_train)\n",
    "# print(X_test)\n",
    "print(Y_train)\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training we will only be working with X_train from here on down\n",
    "Now that we have our training and test data we will run a KNN model on the training data with k-fold validation for hyperparameter tunning (what is a good value of k, distance measure to use, ect...). Then once we have a decent value of k we will \"retrain\" the model on the entire training data set and use that model on the test data which has never been seen and use the error from that as an estimation of $E_{new}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a trained KNN classifier that uses cross validation and grid search to find the best hyperparameters\n",
    "def get_fitted_KNN(X,Y):\n",
    "    #these are the hyperparameters that we are using Gridsearch to find\n",
    "    parameters = {\"n_neighbors\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], \"p\" : [1,2,3]}\n",
    "    #running grid search over a KNN model with 25 fold cross validation.\n",
    "    classifier = skl_ms.GridSearchCV(skl_nb.KNeighborsClassifier(), parameters, cv=25)\n",
    "    #fit the best classifier\n",
    "    classifier.fit(X,Y)\n",
    "    #return it\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see the expected $E_{new}$ of the training data only using cross validation and grid search in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 11, 'p': 1}\n",
      "0.8694720965309201\n"
     ]
    }
   ],
   "source": [
    "# print(np.array(Y_train.values.tolist()).reshape(-1,))\n",
    "classifier = get_fitted_KNN(X_train,np.array(Y_train.values.tolist()).reshape(-1,))\n",
    "print(classifier.best_params_)\n",
    "print(classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to hyperparameter tune and cross validate at the same time we will execute a semi-gridsearch method to determine which features we should use.  \n",
    "\n",
    "Since the gridsearch in Sklearn uses cross validation we can assume the score it returns is an estiamtion of $E_{new}$ (even though this is an invalid estimation for the true $E_{new}$) for the \"training\" data. This is the score we want to try and increase because we are focusing on accuracy.  \n",
    "\n",
    "So we will start with all the features and remove each one individually and see if the score increases. The feature removal that increases the score the most will be used and we will continue to do this until we plateau. Then that final model will be the one we use on the true test set to get our approximation of $E_{new}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will go through several different hyperparameters to hopefully tune the KNN model and find a good one\n",
    "def find_a_good_KNN(df = X_train.join(Y_train)):\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnecessary code\n",
    "\n",
    "#this will run k_folds cross validation with the passed hyperparameters\n",
    "#returns the approximation of the accuracy of the model\n",
    "# def run_k_folds(df = X_train.join(Y_train), folds = 5):\n",
    "#     #setting up our kfolds cross validation\n",
    "#     kf = skl_ms.KFold(folds, shuffle= True)\n",
    "#     #getting the column list so we can separate into X and Y\n",
    "#     cols = df.columns.tolist()\n",
    "#     ycol = \"increase_stock\"\n",
    "#     #only the x columns\n",
    "#     cols.remove(ycol)\n",
    "#     #will be the mean accuracy of the model. This is what we return\n",
    "#     score = 0\n",
    "#     parameters = []\n",
    "#     # print(df)\n",
    "#     # print(cols)\n",
    "#     #loop through all the training and test data\n",
    "#     for i, (train_index, test_index) in enumerate(kf.split(df)):\n",
    "#         #get the specific training data\n",
    "#         train = df.loc[train_index]\n",
    "#         # print(train)\n",
    "#         #get the specific testing data\n",
    "#         test = df.loc[test_index]\n",
    "#         #make a KNN classifier and fit it \n",
    "#         classifier = get_fitted_KNN(X = train[cols], Y=train[ycol])\n",
    "#         #get the score using the k folds test data set\n",
    "#         print(classifier.best_params_)\n",
    "#         parameters.append(classifier.best_params_)\n",
    "#         score += classifier.score(test[cols], test[ycol])\n",
    "#     print(parameters)\n",
    "#     print(Counter(parameters))\n",
    "#     return score/folds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
